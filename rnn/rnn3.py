import tensorflow as tf
import numpy as np

tf.reset_default_graph()

# Create input data
X = np.random.randn(2, 10, 8)

# The second example is of length 6 
X[1,6:] = 0
X_lengths = [10, 6]

cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)

outputs, last_states = tf.nn.dynamic_rnn(
    cell=cell,
    dtype=tf.float64,
    sequence_length=X_lengths,
    inputs=X)

result = tf.contrib.learn.run_n(
    {"outputs": outputs, "last_states": last_states},
    n=1,
    feed_dict=None)

assert result[0]["outputs"].shape == (2, 10, 64)
print(result[0]["outputs"])

# Outputs for the second example past past length 6 should be 0
assert (result[0]["outputs"][1,7,:] == np.zeros(cell.output_size)).all()

'''
[[[ 0.13521753  0.42082712 -0.36560615  1.18797346  0.74748476 -0.8086928
    2.58016927 -0.3566673 ]
  [-1.04574152  0.63453619  0.26457436  0.49701075 -1.02507534  0.18510239
    0.79783804  0.41403198]
  [ 0.40208648  0.98673919  0.72025312  0.81101413  0.807092   -1.14777511
   -1.84919013 -1.37228908]
  [ 0.40076736  0.41960242 -0.62767148 -0.10449051  0.63914975  0.42538667
    0.80049815 -0.57288203]
  [ 1.91414729  0.57657649  1.09077777 -1.07860556 -1.14829106 -0.12596804
   -0.70178942 -2.40649859]
  [ 1.03293245  0.40709064 -1.09328517 -1.13312369  1.32707369 -0.96502665
   -0.40342333  0.23168009]
  [ 1.12088773  0.07411323  0.55283031 -0.00872981  0.12959621  1.59566835
   -0.12839988  0.26704475]
  [ 0.01646623 -2.22684874 -0.15037479  1.4882305   1.09910949  1.02527159
   -0.91727717  1.34485321]
  [-0.27418702 -1.53300257  1.26379812 -1.24403342 -0.79664755  0.52673873
   -0.70795183  1.28316646]
  [ 1.23062268 -1.07200422  1.13292872 -1.02254523  0.50724873  0.28164708
   -1.64964422 -1.48088504]]

 [[-1.49937737 -0.51921024  0.1973904   0.12604628  1.44150735  0.38427006
    1.01263847  0.18997037]
  [ 1.31227059  1.91236781  0.95830966  0.57986073  0.70810177  0.22242148
    0.07092756 -1.26043658]
  [-0.88080223  2.0759578  -0.87786439  0.39232249 -0.11746068  0.16071953
   -0.53917608 -1.09731832]
  [ 0.42595748 -0.66243936 -0.21126507  0.76846845  1.2532389  -0.22849864
    0.23455733  1.47200967]
  [-0.04929768  0.53321937 -0.65557128  0.71996234 -1.67321731 -2.29121969
    1.15764284  0.04664426]
  [-1.58219789 -0.47403596 -0.21389189  0.98685078  0.58407043 -0.27699674
   -0.03742527 -0.34155424]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.        ]
  [ 0.          0.          0.          0.          0.          0.          0.
    0.        ]]]
[[[-0.05790509 -0.06376177  0.07623013 ...,  0.00254334 -0.06627023
    0.00037523]
  [-0.02267772 -0.02509754  0.20135878 ..., -0.06869061 -0.08863505
   -0.13080868]
  [-0.07336317 -0.02021471  0.01131239 ...,  0.05102125 -0.03986029
   -0.07991829]
  ..., 
  [ 0.04461174  0.182489    0.082208   ...,  0.18600834  0.00291214
    0.02338186]
  [ 0.09587871  0.23881635  0.01076383 ...,  0.03265467  0.18734397
    0.03709692]
  [ 0.02650089  0.17294148 -0.11866832 ...,  0.11052023  0.30153297
    0.12581679]]

 [[ 0.0046928  -0.06808419 -0.03048539 ..., -0.00321795  0.0340123
   -0.0069468 ]
  [-0.10212935 -0.07284839 -0.01321398 ...,  0.10106365 -0.01971847
   -0.06554879]
  [-0.09971295 -0.06018621  0.01408384 ...,  0.09478363 -0.05301969
   -0.17624957]
  ..., 
  [ 0.          0.          0.         ...,  0.          0.          0.        ]
  [ 0.          0.          0.         ...,  0.          0.          0.        ]
  [ 0.          0.          0.         ...,  0.          0.          0.        ]]]
  '''